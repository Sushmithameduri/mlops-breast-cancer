# ðŸ§  MLOps Breast Cancer Classification Pipeline

<p align="center">

<!-- Tech Stack Badges -->
<img src="https://img.shields.io/badge/Python-3.9+-blue?logo=python&logoColor=white" />
<img src="https://img.shields.io/badge/scikit--learn-ML-orange?logo=scikitlearn&logoColor=white" />
<img src="https://img.shields.io/badge/MLflow-Experiment%20Tracking-blue?logo=mlflow&logoColor=white" />
<img src="https://img.shields.io/badge/SQLite-Database-lightgrey?logo=sqlite&logoColor=blue" />
<img src="https://img.shields.io/badge/Pytest-Testing-green?logo=pytest&logoColor=white" />
<img src="https://img.shields.io/badge/GitHub%20Actions-CI%2FCD-black?logo=githubactions&logoColor=white" />
<img src="https://img.shields.io/badge/MLOps-Production%20Ready-red" />

</p>

An end-to-end **production-style MLOps project** that trains, validates, registers, and version-controls a machine learning model using MLflow and CI automation.

This project demonstrates real-world MLOps practices including:

- âœ… Reproducible training
- âœ… Feature scaling
- âœ… Model validation testing
- âœ… MLflow experiment tracking
- âœ… Model Registry with versioning
- âœ… SQLite backend (production-ready)
- âœ… CI pipeline validation with GitHub Actions
- âœ… Automated quality threshold enforcement

---

# ðŸ“Œ Project Overview

We train a **Logistic Regression classifier** on the Breast Cancer dataset to predict malignant vs benign tumors.

Dataset source:
- `sklearn.datasets.load_breast_cancer`

Model:
- `LogisticRegression`
- `StandardScaler`
- Accuracy â‰ˆ **97%**

---

# ðŸ— Architecture

```
.
â”œâ”€â”€ app/
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ scaler.pkl
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_model.py
â”œâ”€â”€ mlflow.db
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

---

# ðŸš€ How to Run

## 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate
```

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## 2ï¸âƒ£ Train the Model

```bash
python app/train.py
```

This will:

- Create `mlflow.db`
- Log experiment metrics
- Register model as `BreastCancerModel`
- Save artifacts in `/models`

Expected accuracy:

```
~0.97
```

---

## 3ï¸âƒ£ Run Tests (Model Validation)

```bash
pytest -v
```

The test:

- Loads `model.pkl`
- Loads `scaler.pkl`
- Runs inference
- Computes accuracy
- Asserts accuracy > 0.85

This ensures:

âœ” Model quality does not degrade  
âœ” CI fails if performance drops  
âœ” Artifacts are valid  

---

# ðŸ“Š MLflow Tracking

Tracking backend:

```
sqlite:///mlflow.db
```

Launch UI:

```bash
mlflow ui
```

Open:

```
http://127.0.0.1:5000
```

You can view:

- Parameters
- Metrics
- Artifacts
- Model versions
- Registry lifecycle stages

---

# ðŸ§ª CI Integration

GitHub Actions pipeline:

- Installs dependencies
- Trains model
- Runs pytest
- Fails if:
  - Accuracy < threshold
  - Artifacts missing
  - Code errors occur

Green check = production-safe model.

---

# ðŸ† MLOps Capabilities Demonstrated

### âœ” Model Registry
Version-controlled ML lifecycle management.

### âœ” Reproducibility
Fixed seed, controlled solver, SQLite tracking backend.

### âœ” Performance Gating
Automated accuracy threshold enforcement in CI.

### âœ” Artifact Management
Model and scaler saved independently to ensure proper inference.

---

# ðŸ›  Tech Stack

- Python
- scikit-learn
- MLflow
- SQLite
- Pytest
- GitHub Actions
- Git
- MLOps Best Practices

---

# ðŸ”® Future Enhancements

- Docker containerization
- REST API deployment
- Auto-promotion to Production based on metrics
- Drift detection
- Data versioning
- Model comparison across versions

---

# ðŸ‘©â€ðŸ’» Author

**Sushmitha**  
MS in Data Science  
Building reliable, production-grade ML systems.
